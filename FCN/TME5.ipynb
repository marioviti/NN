{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tme6 import CirclesData\n",
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "def meanCrossEntropyLoss(Y,Y_):\n",
    "    mce = - th.mean(Y*th.log(Y_),1,keepdim=True)\n",
    "    return mce\n",
    "\n",
    "def loss_accuracy(Y,Y_):\n",
    "    loss = meanCrossEntropyLoss(Y,Y_)\n",
    "    N = Y.shape[0]\n",
    "    _, indY = th.max(Y,1)\n",
    "    _, ind_Y = th.max(Y_,1)\n",
    "    tptn = th.sum(indY == ind_Y) * 100\n",
    "    accuracy = tptn/float(N)\n",
    "    return loss,accuracy\n",
    "    \n",
    "def init_params(nx,nh,ny,sigma=0.3):\n",
    "    params = {}\n",
    "    params['Wh'] = th.randn(nh,nx)*sigma\n",
    "    params['bh'] = th.randn(nh,1)*sigma\n",
    "    params['Wy'] = th.randn(ny,nh)*sigma\n",
    "    params['by'] = th.randn(ny,1)*sigma\n",
    "    return params\n",
    "\n",
    "def softmax(_y):\n",
    "    z = th.sum(th.exp(_y),1,keepdim=True)\n",
    "    return th.exp(_y)/z.expand_as(_y)\n",
    "\n",
    "def forward(X,params):\n",
    "    N = X.shape[0]\n",
    "    nh,nx = params['Wh'].shape\n",
    "    ny,nh = params['Wy'].shape\n",
    "    Wht = params['Wh'].t()\n",
    "    Wyt = params['Wy'].t()\n",
    "    bh = params['bh']\n",
    "    by = params['by']\n",
    "    \n",
    "    H_= X.mm(Wht) + bh.expand(nh,N).t()\n",
    "    H = th.tanh(H_)\n",
    "    Y_ = H.mm(Wyt) + by.expand(ny,N).t()\n",
    "    Yh = softmax(Y_)\n",
    "    \n",
    "    params['X'] = X\n",
    "    params['H_']  = H_\n",
    "    params['H'] = H\n",
    "    params['Y_']  = Y_\n",
    "    params['Yh'] = Yh\n",
    "    return params\n",
    "\n",
    "def print_params(params):\n",
    "    keys = params.keys()\n",
    "    X = params['X'] if 'X' in keys else None\n",
    "    Y = params['Y'] if 'Y' in keys else None\n",
    "    Wh = params['Wh'] if 'Wh' in keys else None\n",
    "    bh = params['bh'] if 'bh' in keys else None\n",
    "    H_ = params['H_'] if 'H_' in keys else None\n",
    "    H = params['H'] if 'H' in keys else None\n",
    "    Wy = params['Wy'] if 'Wy' in keys else None\n",
    "    by = params['by'] if 'by' in keys else None\n",
    "    Y_ = params['Y_'] if 'Y_' in keys else None\n",
    "    Yh = params['Yh'] if 'Yh' in keys else None\n",
    "    print ( '\\\n",
    "X: {}Y: {}\\\n",
    "Wh: {}bh: {}\\\n",
    "XWht+bh=H_: {}tahn(H_)=H: {}\\\n",
    "Wy: {}by: {}\\n\\\n",
    "XWyt+by=Y_: {}Softmax(Y_)=Yh: {}\\n\\\n",
    "'.format(X,Y,Wh,bh,H_,H,Wy,by,Y_,Yh) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      " 0.9042 -0.1938\n",
      " 0.9349  0.0266\n",
      " 1.2184 -0.0958\n",
      "[torch.FloatTensor of size 3x2]\n",
      "Y: \n",
      " 1  0\n",
      " 1  0\n",
      " 1  0\n",
      "[torch.FloatTensor of size 3x2]\n",
      "Wh: \n",
      " 0.1109  0.1859\n",
      " 0.3025 -0.2389\n",
      "-0.0404 -0.4613\n",
      " 0.2526 -0.0468\n",
      "[torch.FloatTensor of size 4x2]\n",
      "bh: \n",
      " 0.2257\n",
      "-0.0286\n",
      "-0.2388\n",
      "-0.6001\n",
      "[torch.FloatTensor of size 4x1]\n",
      "XWht+bh=H_: \n",
      " 0.2900  0.2913 -0.1859 -0.3627\n",
      " 0.3344  0.2479 -0.2888 -0.3652\n",
      " 0.3431  0.3629 -0.2438 -0.2879\n",
      "[torch.FloatTensor of size 3x4]\n",
      "tahn(H_)=H: \n",
      " 0.2821  0.2833 -0.1838 -0.3475\n",
      " 0.3225  0.2430 -0.2811 -0.3498\n",
      " 0.3302  0.3478 -0.2391 -0.2802\n",
      "[torch.FloatTensor of size 3x4]\n",
      "Wy: \n",
      " 0.0308 -0.1972  0.0997  0.2369\n",
      " 0.0522 -0.1701  0.3811  0.2591\n",
      "[torch.FloatTensor of size 2x4]\n",
      "by: \n",
      " 0.8328\n",
      "-0.2246\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "XWyt+by=Y_: \n",
      " 0.6849 -0.4181\n",
      " 0.6839 -0.4468\n",
      " 0.6841 -0.4302\n",
      "[torch.FloatTensor of size 3x2]\n",
      "Softmax(Y_)=Yh: \n",
      " 0.7508  0.2492\n",
      " 0.7560  0.2440\n",
      " 0.7529  0.2471\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "\n",
      "MCE loss: \n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[torch.FloatTensor of size 3x1]\n",
      ", accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "params={}\n",
    "data = CirclesData()\n",
    "Xtrain = data.Xtrain\n",
    "N = Xtrain.shape[0] \n",
    "nx = Xtrain.shape[1]\n",
    "# hidden units\n",
    "nh = 4\n",
    "# classes X\n",
    "ny = 2\n",
    "#batch_size = N\n",
    "params = init_params(nx,nh,ny)\n",
    "params = forward(Xtrain[0:batch_size], params)\n",
    "Y = data.Ytrain[0:batch_size]\n",
    "params['Y'] = Y\n",
    "loss,acc = loss_accuracy(Y,params['Y_'])\n",
    "print_params(params)\n",
    "print('MCE loss: {}, accuracy: {}'.format(loss,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute forward with tensors\n",
    "\n",
    "## Remarks\n",
    "* doint Xtrain[0:1] returns a size 1XN tensor while doing so Xtrain[0] return a size N tensor.\n",
    "* don't mix numpy and torch (too much)\n",
    "* $XW^t$ instead of $WX^t$ because $X >> W$ (for large batches).\n",
    "* the previus point implies that you must expand bias by rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backward\n",
    "\n",
    "def print_grads(grads):\n",
    "    keys = grads.keys()\n",
    "    \n",
    "    DYh = grads['DYh'] if 'DYh' in keys else None\n",
    "    DWy = grads['DWy'] if 'DWy' in keys else None\n",
    "    Dby = grads['Dby'] if 'Dby' in keys else None\n",
    "    DH_ = grads['DH_'] if 'DH_' in keys else None\n",
    "    DWh = grads['DWh'] if 'DWh' in keys else None\n",
    "    Dbh = grads['Dbh'] if 'Dbh' in keys else None\n",
    "    print ( '\\\n",
    "DYh: {}DWy: {}Dby: {}DH_: {}DWh: {}Dbh: {}\\\n",
    "'.format(DYh,DWy,Dby,DH_,DWh,Dbh) )\n",
    "\n",
    "def backward(params):\n",
    "    grads = {}\n",
    "    Y  = params['Y']\n",
    "    Yh = params['Yh']\n",
    "    X  = params['X']\n",
    "    H  = params['H']\n",
    "    Wy = params['Wy']\n",
    "    \n",
    "    DYh = Yh-Y\n",
    "    DWy = DYh.t().mm(H)\n",
    "    Dby = th.sum(DYh,0,keepdim=True).t()\n",
    "    DH_ = DYh.mm(Wy)*(1-H**2)\n",
    "    DWh = DH_.t().mm(X)\n",
    "    Dbh = th.sum(DH_,0,keepdim=True).t()\n",
    "    \n",
    "    grads['DYh'] = DYh\n",
    "    grads['DWy'] = DWy\n",
    "    grads['Dby'] = Dby\n",
    "    grads['DH_'] = DH_\n",
    "    grads['DWh'] = DWh\n",
    "    grads['Dbh'] = Dbh\n",
    "    return grads\n",
    "\n",
    "def sgd(params, grads, eps=1e-3):\n",
    "    DWy = grads['DWy']\n",
    "    Dby = grads['Dby']\n",
    "    DWh = grads['DWh']\n",
    "    Dbh = grads['Dbh']\n",
    "    \n",
    "    Wy = params['Wy']\n",
    "    by = params['by']\n",
    "    Wh = params['Wh']\n",
    "    bh = params['bh']\n",
    "    \n",
    "    Wy_t1 = Wy - eps*DWy\n",
    "    by_t1 = by - eps*Dby\n",
    "    Wh_t1 = Wh - eps*DWh\n",
    "    bh_t1 = bh - eps*Dbh\n",
    "    \n",
    "    params['Wy'] = Wy_t1\n",
    "    params['by'] = by_t1\n",
    "    params['Wh'] = Wh_t1\n",
    "    params['bh'] = bh_t1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 51.5\n",
      "accuracy: 56.5\n",
      "accuracy: 60.5\n",
      "accuracy: 61.0\n",
      "accuracy: 61.5\n",
      "accuracy: 63.0\n",
      "accuracy: 64.0\n",
      "accuracy: 65.5\n",
      "accuracy: 65.5\n",
      "accuracy: 65.5\n",
      "accuracy: 64.5\n",
      "accuracy: 63.5\n",
      "accuracy: 62.5\n",
      "accuracy: 62.5\n",
      "accuracy: 62.0\n",
      "accuracy: 61.5\n",
      "accuracy: 62.0\n",
      "accuracy: 62.5\n",
      "accuracy: 63.0\n",
      "accuracy: 63.0\n",
      "accuracy: 63.0\n",
      "accuracy: 63.0\n",
      "accuracy: 63.0\n",
      "accuracy: 63.0\n",
      "accuracy: 63.0\n",
      "accuracy: 63.0\n",
      "accuracy: 63.5\n",
      "accuracy: 64.0\n",
      "accuracy: 65.0\n",
      "accuracy: 65.5\n",
      "accuracy: 66.0\n",
      "accuracy: 66.5\n",
      "accuracy: 66.5\n",
      "accuracy: 66.5\n",
      "accuracy: 67.5\n",
      "accuracy: 67.5\n",
      "accuracy: 67.5\n",
      "accuracy: 67.5\n",
      "accuracy: 67.5\n",
      "accuracy: 67.5\n",
      "accuracy: 68.0\n",
      "accuracy: 67.5\n",
      "accuracy: 68.0\n",
      "accuracy: 68.0\n",
      "accuracy: 68.0\n",
      "accuracy: 67.5\n",
      "accuracy: 67.0\n",
      "accuracy: 67.5\n",
      "accuracy: 67.0\n",
      "accuracy: 67.5\n",
      "accuracy: 68.0\n",
      "accuracy: 69.0\n",
      "accuracy: 69.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.0\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.0\n",
      "accuracy: 68.0\n",
      "accuracy: 68.0\n",
      "accuracy: 68.0\n",
      "accuracy: 68.0\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.0\n",
      "accuracy: 68.5\n",
      "accuracy: 68.5\n",
      "accuracy: 69.0\n",
      "accuracy: 69.0\n",
      "accuracy: 69.0\n",
      "accuracy: 69.0\n",
      "accuracy: 69.0\n",
      "accuracy: 69.0\n",
      "accuracy: 69.0\n",
      "accuracy: 69.0\n",
      "accuracy: 69.0\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.0\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 69.5\n",
      "accuracy: 70.0\n",
      "accuracy: 70.5\n",
      "accuracy: 71.0\n",
      "accuracy: 71.5\n",
      "accuracy: 71.5\n",
      "accuracy: 71.5\n",
      "accuracy: 72.0\n",
      "accuracy: 73.0\n",
      "accuracy: 73.0\n",
      "accuracy: 73.5\n",
      "accuracy: 73.5\n",
      "accuracy: 73.5\n",
      "accuracy: 74.0\n",
      "accuracy: 74.0\n",
      "accuracy: 74.0\n",
      "accuracy: 74.5\n",
      "accuracy: 75.0\n",
      "accuracy: 75.0\n",
      "accuracy: 75.5\n",
      "accuracy: 75.5\n",
      "accuracy: 75.5\n",
      "accuracy: 75.5\n",
      "accuracy: 75.5\n",
      "accuracy: 75.5\n",
      "accuracy: 76.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 77.5\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.0\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 78.5\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.0\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 79.5\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.0\n",
      "accuracy: 80.5\n",
      "accuracy: 80.5\n",
      "accuracy: 80.5\n",
      "accuracy: 80.5\n",
      "accuracy: 80.5\n",
      "accuracy: 80.5\n",
      "accuracy: 80.5\n",
      "accuracy: 80.5\n",
      "accuracy: 80.5\n",
      "accuracy: 81.5\n",
      "accuracy: 81.5\n",
      "accuracy: 81.5\n",
      "accuracy: 81.5\n",
      "accuracy: 82.0\n",
      "accuracy: 82.0\n",
      "accuracy: 82.0\n",
      "accuracy: 82.5\n",
      "accuracy: 82.5\n",
      "accuracy: 82.5\n",
      "accuracy: 82.5\n",
      "accuracy: 82.5\n",
      "accuracy: 82.5\n",
      "accuracy: 82.5\n",
      "accuracy: 83.0\n",
      "accuracy: 83.5\n",
      "accuracy: 83.5\n",
      "accuracy: 83.5\n",
      "accuracy: 84.0\n",
      "accuracy: 84.0\n",
      "accuracy: 84.0\n",
      "accuracy: 84.5\n",
      "accuracy: 84.5\n",
      "accuracy: 84.5\n",
      "accuracy: 85.0\n",
      "accuracy: 85.5\n",
      "accuracy: 85.5\n",
      "accuracy: 85.5\n",
      "accuracy: 86.0\n",
      "accuracy: 86.0\n",
      "accuracy: 86.0\n",
      "accuracy: 86.5\n",
      "accuracy: 86.5\n",
      "accuracy: 86.5\n",
      "accuracy: 87.0\n",
      "accuracy: 87.0\n",
      "accuracy: 87.0\n",
      "accuracy: 87.0\n",
      "accuracy: 87.0\n",
      "accuracy: 87.0\n",
      "accuracy: 87.5\n",
      "accuracy: 87.5\n",
      "accuracy: 87.5\n",
      "accuracy: 88.0\n",
      "accuracy: 88.0\n",
      "accuracy: 88.0\n",
      "accuracy: 88.5\n",
      "accuracy: 88.5\n",
      "accuracy: 89.0\n",
      "accuracy: 89.5\n",
      "accuracy: 90.0\n",
      "accuracy: 90.0\n",
      "accuracy: 90.5\n",
      "accuracy: 90.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.5\n",
      "accuracy: 90.5\n",
      "accuracy: 91.0\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 91.5\n",
      "accuracy: 92.0\n",
      "accuracy: 92.0\n",
      "accuracy: 92.0\n",
      "accuracy: 92.0\n",
      "accuracy: 92.5\n",
      "accuracy: 92.5\n",
      "accuracy: 92.5\n",
      "accuracy: 92.5\n",
      "accuracy: 92.5\n",
      "accuracy: 93.0\n",
      "accuracy: 93.5\n",
      "accuracy: 93.5\n",
      "accuracy: 93.5\n",
      "accuracy: 93.5\n",
      "accuracy: 94.0\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.5\n",
      "accuracy: 95.5\n",
      "accuracy: 95.5\n",
      "accuracy: 95.5\n",
      "accuracy: 95.5\n",
      "accuracy: 95.5\n",
      "accuracy: 95.5\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 93.5\n",
      "accuracy: 93.5\n",
      "accuracy: 93.5\n",
      "accuracy: 93.5\n",
      "accuracy: 93.5\n",
      "accuracy: 93.5\n",
      "accuracy: 93.5\n",
      "accuracy: 93.5\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.0\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 94.5\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n",
      "accuracy: 95.0\n"
     ]
    }
   ],
   "source": [
    "data = CirclesData()\n",
    "X = data.Xtrain\n",
    "Y = data.Ytrain\n",
    "N = X.shape[0] \n",
    "nx = X.shape[1]\n",
    "ny = Y.shape[1]\n",
    "# hidden units\n",
    "nh = 5\n",
    "params = init_params(nx,nh,ny)\n",
    "params['Y'] = Y\n",
    "# non stocastic.\n",
    "for i in range(1000):\n",
    "    params = forward(X,params)\n",
    "    grads = backward(params)\n",
    "    #print_grads(grads)\n",
    "    params = sgd(params,grads)\n",
    "    #print_params(params)\n",
    "    loss, acc = loss_accuracy(params['Y'],params['Y_'])\n",
    "    print('accuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 35.0\n",
      "accuracy: 35.0\n",
      "accuracy: 37.0\n",
      "accuracy: 44.0\n",
      "accuracy: 36.0\n",
      "accuracy: 40.0\n",
      "accuracy: 39.0\n",
      "accuracy: 43.0\n",
      "accuracy: 47.0\n",
      "accuracy: 45.0\n",
      "accuracy: 51.0\n",
      "accuracy: 52.0\n",
      "accuracy: 45.0\n",
      "accuracy: 47.0\n",
      "accuracy: 48.0\n",
      "accuracy: 51.0\n",
      "accuracy: 44.0\n",
      "accuracy: 41.0\n",
      "accuracy: 43.0\n",
      "accuracy: 40.0\n"
     ]
    }
   ],
   "source": [
    "data = CirclesData()\n",
    "X = data.Xtrain\n",
    "Y = data.Ytrain\n",
    "N = X.shape[0] \n",
    "nx = X.shape[1]\n",
    "ny = Y.shape[1]\n",
    "# hidden units\n",
    "nh = 5\n",
    "params = {}\n",
    "grads = {}\n",
    "params = init_params(nx,nh,ny)\n",
    "epocs = 20\n",
    "batch_size = 100\n",
    "acc = 0\n",
    "for i in range(epocs):\n",
    "    batch = th.randperm(N)[:batch_size]\n",
    "    batch = batch\n",
    "    params['Y'] = Y[batch]\n",
    "    params = forward(X[batch],params)\n",
    "    grads = backward(params)\n",
    "    #print_grads(grads)\n",
    "    params = sgd(params,grads)\n",
    "    #print_params(params)\n",
    "    loss,acc = loss_accuracy(params['Y'],params['Y_'])\n",
    "    print('accuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Basic_nn():\n",
    "    def __init__(self,hidden_neurons=4):\n",
    "        self.nh = hidden_neurons\n",
    "        self.acc_log = []\n",
    "\n",
    "    def train_nn(self,X,Y,Nbatch=100,eps=1e-3,epochs=1000):\n",
    "        N = X.shape[0] \n",
    "        nx = X.shape[1]\n",
    "        ny = Y.shape[1]\n",
    "        nh = self.nh\n",
    "        params = init_params(nx,nh,ny)\n",
    "        for i in range(epochs):\n",
    "            params = forward(X[i*Nbatch:(i+1)*Nbatch],params)\n",
    "            params['Y'] = Y[i*Nbatch:(i+1)*Nbatch]\n",
    "            grads = backward(params)\n",
    "            params = sgd(params,eps)\n",
    "            self.acc_log += [loss_accuracy(params['Y'],params['Y_'])]\n",
    "        self.params = params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8fc9ffd7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "x = np.random.randn(100000)\n",
    "plt.hist(x)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
